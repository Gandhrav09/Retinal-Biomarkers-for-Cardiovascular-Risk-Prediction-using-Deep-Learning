{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","authorship_tag":"ABX9TyMlhivjGtVwCjiewhvkLgF1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","source":["pip install gradio"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ebuFZrEwOr9f","executionInfo":{"status":"ok","timestamp":1738999155489,"user_tz":-330,"elapsed":1985,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}},"outputId":"df214366-d7e4-4a46-ecab-1b2d01b67942"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.15.0)\n","Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (23.2.1)\n","Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.7.1)\n","Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.8)\n","Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n","Requirement already satisfied: gradio-client==1.7.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.7.0)\n","Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n","Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.5)\n","Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.1.5)\n","Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.26.4)\n","Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.15)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n","Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n","Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.1.0)\n","Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.6)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n","Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n","Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n","Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.9.5)\n","Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n","Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n","Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.45.3)\n","Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n","Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.1)\n","Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.12.2)\n","Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (2025.2.0)\n","Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.7.0->gradio) (14.2)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.1.31)\n","Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.7)\n","Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.17.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.0->gradio) (2.27.2)\n","Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n","Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n","Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.3.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"]}]},{"cell_type":"code","source":["pip install lightly"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sJTRh5DAs_gu","executionInfo":{"status":"ok","timestamp":1738999161800,"user_tz":-330,"elapsed":1735,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}},"outputId":"2218152b-e4bc-4fbe-defc-ba8da4d37417"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: lightly in /usr/local/lib/python3.11/dist-packages (1.5.18)\n","Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.11/dist-packages (from lightly) (2025.1.31)\n","Requirement already satisfied: hydra-core>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (1.3.2)\n","Requirement already satisfied: lightly_utils~=0.0.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (0.0.2)\n","Requirement already satisfied: numpy>=1.18.1 in /usr/local/lib/python3.11/dist-packages (from lightly) (1.26.4)\n","Requirement already satisfied: python_dateutil>=2.5.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.9.0.post0)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.32.3)\n","Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.11/dist-packages (from lightly) (1.17.0)\n","Requirement already satisfied: tqdm>=4.44 in /usr/local/lib/python3.11/dist-packages (from lightly) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from lightly) (2.5.1+cpu)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from lightly) (0.20.1+cpu)\n","Requirement already satisfied: pydantic>=1.10.5 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.10.6)\n","Requirement already satisfied: pytorch_lightning>=1.0.4 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.5.0.post0)\n","Requirement already satisfied: urllib3>=1.25.3 in /usr/local/lib/python3.11/dist-packages (from lightly) (2.3.0)\n","Requirement already satisfied: aenum>=3.1.11 in /usr/local/lib/python3.11/dist-packages (from lightly) (3.1.15)\n","Requirement already satisfied: omegaconf<2.4,>=2.2 in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (2.3.0)\n","Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (4.9.3)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from hydra-core>=1.0.0->lightly) (24.2)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from lightly_utils~=0.0.0->lightly) (11.1.0)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (2.27.2)\n","Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=1.10.5->lightly) (4.12.2)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (6.0.2)\n","Requirement already satisfied: fsspec>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2025.2.0)\n","Requirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (1.6.1)\n","Requirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_lightning>=1.0.4->lightly) (0.12.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->lightly) (3.10)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.17.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (3.1.5)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->lightly) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->lightly) (1.3.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (3.11.12)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch_lightning>=1.0.4->lightly) (75.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->lightly) (2.1.5)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (2.4.6)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch_lightning>=1.0.4->lightly) (1.18.3)\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jcyuo7aluX2I","executionInfo":{"status":"ok","timestamp":1738999191261,"user_tz":-330,"elapsed":25476,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}},"outputId":"dfe4f938-c458-4a83-f1c3-2a6995dba5aa"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["dataset_path = \"/content/drive/My Drive/Datset/selected\"  # Adjust to your folder structure\n"],"metadata":{"id":"FfBzldCfydsb","executionInfo":{"status":"ok","timestamp":1738999196024,"user_tz":-330,"elapsed":589,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","execution_count":5,"metadata":{"id":"W9TzFPHma538","executionInfo":{"status":"ok","timestamp":1738999232623,"user_tz":-330,"elapsed":34673,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}}},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers\n","\n","# Data augmentation for SimCLR\n","data_augmentation = tf.keras.Sequential([\n","    layers.RandomFlip(\"horizontal\"),\n","    layers.RandomRotation(0.2),\n","    layers.RandomZoom(0.2),\n","])\n"]},{"cell_type":"code","source":["# Encoder Model\n","def create_encoder(input_shape=(224, 224, 3)):\n","    base_model = tf.keras.applications.ResNet50(include_top=False, weights=None, input_shape=input_shape)\n","    encoder = tf.keras.Sequential([\n","        base_model,\n","        layers.GlobalAveragePooling2D(),\n","    ])\n","    return encoder\n","\n","encoder = create_encoder()\n","\n","# Contrastive Loss for SimCLR\n","def contrastive_loss(projections_1, projections_2, temperature=0.1):\n","    projections_1 = tf.math.l2_normalize(projections_1, axis=1)\n","    projections_2 = tf.math.l2_normalize(projections_2, axis=1)\n","\n","    # Similarity matrix\n","    similarity_matrix = tf.matmul(projections_1, projections_2, transpose_b=True)\n","    labels = tf.eye(similarity_matrix.shape[0])  # Positive pairs on diagonal\n","    return tf.keras.losses.CategoricalCrossentropy(from_logits=True)(labels, similarity_matrix / temperature)\n"],"metadata":{"id":"_cgQo32cv_3k","executionInfo":{"status":"ok","timestamp":1738999236631,"user_tz":-330,"elapsed":1195,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n","\n","@tf.function\n","def train_step(batch_images):\n","    with tf.GradientTape() as tape:\n","        augmented_1 = data_augmentation(batch_images)\n","        augmented_2 = data_augmentation(batch_images)\n","\n","        projections_1 = encoder(augmented_1, training=True)\n","        projections_2 = encoder(augmented_2, training=True)\n","\n","        loss = contrastive_loss(projections_1, projections_2)\n","\n","    gradients = tape.gradient(loss, encoder.trainable_variables)\n","    optimizer.apply_gradients(zip(gradients, encoder.trainable_variables))\n","    return loss\n"],"metadata":{"id":"QLPv2bLEwFFY","executionInfo":{"status":"ok","timestamp":1738999249366,"user_tz":-330,"elapsed":364,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["# Load dataset and preprocess\n","def preprocess_image(image_path):\n","    img = tf.keras.preprocessing.image.load_img(image_path, target_size=(224, 224))\n","    img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0\n","    return img_array\n","\n","import os\n","import numpy as np\n","\n","def load_dataset(image_folder):\n","    images = []\n","    for image_name in os.listdir(image_folder):\n","        if image_name.endswith((\".jpg\", \".jpeg\", \".png\")):\n","            images.append(preprocess_image(os.path.join(image_folder, image_name)))\n","    return np.array(images)\n","\n","images = load_dataset(dataset_path)\n","batch_size = 32\n","epochs = 10\n","\n","for epoch in range(epochs):\n","    total_loss = 0\n","    for i in range(0, len(images), batch_size):\n","        batch_images = images[i:i+batch_size]\n","        loss = train_step(batch_images)\n","        total_loss += loss.numpy()\n","    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rV8xHr9n80gf","outputId":"36f53463-44ce-4529-d0af-b1413aa353fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1, Loss: 19.6442\n","Epoch 2, Loss: 13.1485\n","Epoch 3, Loss: 10.9233\n","Epoch 4, Loss: 9.9156\n"]}]},{"cell_type":"code","source":["# Define the encoder model\n","encoder = create_encoder(input_shape=(224, 224, 3))\n","\n","# Build the encoder model by calling it with a dummy input\n","dummy_input = tf.keras.Input(shape=(224, 224, 3))\n","encoder_output = encoder(dummy_input)\n"],"metadata":{"id":"NNUbhv4H-H3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers, Model\n","\n","# Attach classification head\n","x = layers.Dense(128, activation=\"relu\")(encoder_output)\n","x = layers.Dropout(0.5)(x)\n","output = layers.Dense(3, activation=\"softmax\")(x)  # 3 classes: Low, Medium, High\n","\n","# Build the final model\n","model = Model(inputs=dummy_input, outputs=output)\n","\n","# Compile the model\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n"],"metadata":{"id":"SlVas1Mv81CI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tZRO3bdidToG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import os\n","import numpy as np\n","from tensorflow.keras.applications import ResNet50\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","\n","# Load pre-trained ResNet50 without the top classification layer\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(224, 224, 3))\n","\n","def extract_features(image_folder, img_size=(224, 224)):\n","    \"\"\"\n","    Extracts features from images in a folder using a pre-trained model.\n","    Args:\n","        image_folder (str): Path to the folder containing images.\n","        img_size (tuple): Size to resize images.\n","    Returns:\n","        np.ndarray: Extracted features.\n","        list: List of image file paths.\n","    \"\"\"\n","    features = []\n","    image_paths = []\n","\n","    for image_name in os.listdir(image_folder):\n","        if image_name.endswith((\".jpg\", \".jpeg\", \".png\")):\n","            image_path = os.path.join(image_folder, image_name)\n","            img = load_img(image_path, target_size=img_size)\n","            img_array = img_to_array(img) / 255.0  # Normalize pixel values\n","            img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","\n","            # Extract features\n","            feature = base_model.predict(img_array)\n","            features.append(feature.flatten())\n","            image_paths.append(image_path)\n","\n","    return np.array(features), image_paths\n","\n","# Path to the dataset (adjust to your directory)\n","dataset_path = \"/content/drive/My Drive/Datset/temp\"\n","features, image_paths = extract_features(dataset_path)\n","print(f\"Extracted features shape: {features.shape}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6jlm_k6-VoO","executionInfo":{"status":"ok","timestamp":1737721056084,"user_tz":-330,"elapsed":12532,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}},"outputId":"19d4c33b-f106-447a-b9a6-9ac5ceda8115"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n","\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n","Extracted features shape: (10, 2048)\n"]}]},{"cell_type":"code","source":["from sklearn.cluster import KMeans\n","\n","# Apply K-Means clustering\n","num_clusters = 3  # Assume 3 clusters for Low, Medium, High Risk\n","kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n","clusters = kmeans.fit_predict(features)\n","\n","# Map each image to a cluster\n","for path, cluster in zip(image_paths, clusters):\n","    print(f\"Image: {path}, Cluster: {cluster}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZsGyu8bFDsI4","executionInfo":{"status":"ok","timestamp":1737721060963,"user_tz":-330,"elapsed":4887,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}},"outputId":"c1ad40df-88fb-4e60-b824-89c1f53a086b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image: /content/drive/My Drive/Datset/temp/Copy of 8.png, Cluster: 0\n","Image: /content/drive/My Drive/Datset/temp/Copy of 3.png, Cluster: 2\n","Image: /content/drive/My Drive/Datset/temp/Copy of 1.png, Cluster: 0\n","Image: /content/drive/My Drive/Datset/temp/Copy of 9.png, Cluster: 0\n","Image: /content/drive/My Drive/Datset/temp/Copy of 5.png, Cluster: 2\n","Image: /content/drive/My Drive/Datset/temp/Copy of 7.png, Cluster: 0\n","Image: /content/drive/My Drive/Datset/temp/Copy of 2.png, Cluster: 0\n","Image: /content/drive/My Drive/Datset/temp/Copy of 4.png, Cluster: 1\n","Image: /content/drive/My Drive/Datset/temp/Copy of 6.png, Cluster: 1\n","Image: /content/drive/My Drive/Datset/temp/Copy of 10.png, Cluster: 0\n"]}]},{"cell_type":"code","source":["import shutil\n","\n","output_path = \"/content/drive/My Drive/clustered_images\"\n","for path, cluster in zip(image_paths, clusters):\n","    cluster_folder = os.path.join(output_path, str(cluster))\n","    os.makedirs(cluster_folder, exist_ok=True)\n","    shutil.copy(path, cluster_folder)\n"],"metadata":{"id":"AVy00V_IDyhI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras import layers, Model\n","from tensorflow.keras.applications import ResNet50\n","\n","# Data Generators\n","datagen = ImageDataGenerator(rescale=1.0 / 255, validation_split=0.2)\n","\n","train_gen = datagen.flow_from_directory(\n","    output_path, target_size=(224, 224), batch_size=16, class_mode=\"categorical\", subset=\"training\"\n",")\n","val_gen = datagen.flow_from_directory(\n","    output_path, target_size=(224, 224), batch_size=16, class_mode=\"categorical\", subset=\"validation\"\n",")\n","\n","# Load pre-trained ResNet50 and attach classification head\n","base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(224, 224, 3))\n","base_model.trainable = False\n","\n","# Add classification layers\n","inputs = layers.Input(shape=(224, 224, 3))\n","x = base_model(inputs, training=False)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)\n","outputs = layers.Dense(3, activation=\"softmax\")(x)  # 3 clusters\n","model = Model(inputs, outputs)\n","\n","# Compile and train\n","model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n","model.fit(train_gen, validation_data=val_gen, epochs=10)\n","\n","# Save the fine-tuned model\n","model.save(\"pseudo_label_model.h5\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"13e3NVh0EFIr","executionInfo":{"status":"ok","timestamp":1737721093194,"user_tz":-330,"elapsed":26197,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}},"outputId":"22795bed-580d-428c-d791-b7e515d78d4e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Found 9 images belonging to 3 classes.\n","Found 1 images belonging to 3 classes.\n","Epoch 1/10\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:122: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n","  self._warn_if_super_not_called()\n"]},{"output_type":"stream","name":"stdout","text":["\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 17s/step - accuracy: 0.2222 - loss: 1.8669 - val_accuracy: 0.0000e+00 - val_loss: 1.1585\n","Epoch 2/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4444 - loss: 1.3172 - val_accuracy: 1.0000 - val_loss: 0.4786\n","Epoch 3/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.4444 - loss: 1.1700 - val_accuracy: 1.0000 - val_loss: 0.2428\n","Epoch 4/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 824ms/step - accuracy: 0.6667 - loss: 1.2399 - val_accuracy: 1.0000 - val_loss: 0.1669\n","Epoch 5/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 806ms/step - accuracy: 0.5556 - loss: 1.3733 - val_accuracy: 1.0000 - val_loss: 0.1580\n","Epoch 6/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5556 - loss: 1.3697 - val_accuracy: 1.0000 - val_loss: 0.1908\n","Epoch 7/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5556 - loss: 1.5794 - val_accuracy: 1.0000 - val_loss: 0.2606\n","Epoch 8/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 822ms/step - accuracy: 0.5556 - loss: 1.4024 - val_accuracy: 1.0000 - val_loss: 0.3607\n","Epoch 9/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - accuracy: 0.5556 - loss: 1.4659 - val_accuracy: 1.0000 - val_loss: 0.5069\n","Epoch 10/10\n","\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 809ms/step - accuracy: 0.5556 - loss: 1.1107 - val_accuracy: 1.0000 - val_loss: 0.6666\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"]}]},{"cell_type":"code","source":["import gradio as gr\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","from PIL import Image\n","\n","# Load the trained model\n","model = load_model(\"pseudo_label_model.h5\")  # Replace with your model path\n","\n","# Define the prediction function\n","def predict_retina_image(image):\n","    \"\"\"\n","    Predict cardiovascular risk from a retina image.\n","    Args:\n","        image (PIL.Image): Input retina image uploaded by the user.\n","    Returns:\n","        str: Predicted risk and confidence scores.\n","    \"\"\"\n","    try:\n","        # Define cluster names\n","        cluster_names = {0: \"Low Risk\", 1: \"Medium Risk\", 2: \"High Risk\"}\n","\n","        # Preprocess the image\n","        image = image.resize((224, 224))  # Resize to match model input\n","        img_array = np.array(image) / 255.0  # Normalize pixel values\n","        img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n","\n","        # Predict\n","        predictions = model.predict(img_array)\n","        predicted_cluster = np.argmax(predictions)  # Get the cluster with the highest probability\n","        cluster_name = cluster_names[predicted_cluster]  # Map cluster to name\n","\n","        # Confidence scores\n","        confidence_scores = {\n","            cluster_names[i]: round(float(score) * 100, 2)\n","            for i, score in enumerate(predictions[0])\n","        }\n","\n","        # Return results\n","        return f\"Predicted Risk: {cluster_name}\\nConfidence Scores: {confidence_scores}\"\n","\n","    except Exception as e:\n","        return f\"Error: {str(e)}\"\n","\n","# Create Gradio interface\n","interface = gr.Interface(\n","    fn=predict_retina_image,  # The function to call\n","    inputs=gr.Image(type=\"pil\", label=\"Upload Retina Image\"),  # Input: Retina image\n","    outputs=gr.Textbox(label=\"Prediction\"),  # Output: Textbox for results\n","    title=\"Cardiovascular Risk Prediction\",\n","    description=\"Upload a retina image to predict the cardiovascular risk cluster (Low Risk, Medium Risk, High Risk).\",\n",")\n","\n","# Launch the Gradio app\n","if __name__ == \"__main__\":\n","    interface.launch()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":663},"id":"FdPh_zTDIBpU","executionInfo":{"status":"ok","timestamp":1737721099608,"user_tz":-330,"elapsed":6420,"user":{"displayName":"DHAVAN B ISE","userId":"12867438825415523073"}},"outputId":"9184b8f6-3395-4414-abf0-52ad38f2957a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"output_type":"stream","name":"stdout","text":["Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n","\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","* Running on public URL: https://93b483cd12ba27f9c2.gradio.live\n","\n","This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<div><iframe src=\"https://93b483cd12ba27f9c2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"]},"metadata":{}}]}]}